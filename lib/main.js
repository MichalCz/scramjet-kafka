const {ProducerStream} = require("kafka-node");
const {KafkaStream} = require("./kafka-stream");
const scramjet = require("scramjet");
const {StringStream} = scramjet;

/**
 * Scramjet Kafka module exports
 *
 * @type {Object}
 */
const sjKafka = module.exports = {
    KafkaStream,

    /**
     * Fetches a stream from Kafka topic performs declared operations and publishes to the another topic.
     *
     * The transforms as in scramjet can be asynchronous, synchronous, even multi-threaded.
     *
     * {@see https://scramjet.eu/ Scramjet documentation}
     *
     * @param  {Client|KafkaClient} client KafkaNode client to Zookeeper or direcly Kafka
     * @param  {String|Topic} fromTopic topic to consume
     * @param  {UseCallback} use transforms callback or scramjet module
     * @param  {String|Topic} toTopic topic to produce3
     * @return {Promise} resolved when fromTopic stream ends.
     */
    async augment(client, fromTopic, use, toTopic) {    // eslint-disable-line
        return sjKafka.from(client, fromTopic)
            .use(use)
            .produceKafka(client, toTopic);
    },

    /**
     * Consume a topic from kafka and return a new KafkaStream
     *
     * @alias consume
     * @param  {Client|KafkaClient} client KafkaNode client to Zookeeper or direcly Kafka
     * @param {Array.<String|Topic>}  [topics=[]] Topics to pull from Kafka
     * @chainable
     */
    consume(client, topics) {
        if (!Array.isArray(topics))
            topics = [topics];

        return new KafkaStream(client)
            .addTopics(topics)
            .connect()
        ;
    }
};

module.exports.from = module.exports.consume;

/**
 * {@link https://scramjet.eu/docs/string-stream.html Scramjet StringStream} plugin - the following methods are added
 * to all scramjet streams
 */
scramjet.plugin({StringStream: {
    /**
     * Plugin to scramjet::StringStream - push to kafka and pull on the other end.
     *
     * This may be used to allow burst flow above memory limits.
     *
     * @memberof plugin
     * @param  {Client|KafkaClient} client KafkaNode client to Zookeeper or direcly Kafka
     * @param  {String|Topic} [topic=null] topic - will be autogenerated if not given
     * @return {Promise} resolved when fromTopic stream ends.
     */
    viaKafka(client, topic = null) {
        this.produceKafka(client, topic);
        return sjKafka.consume(client, topic);
    },

    /**
     * Send the stream to the specified Kafka topic.
     *
     * @memberof plugin
     * @param  {Client|KafkaClient} client KafkaNode.client
     * @param  {String|Topic} [topic=null] topic - will be autogenerated if not given
     * @return {Promise} resolved when fromTopic stream ends.
     */
    async produceKafka(client, topic) {
        const producer = new ProducerStream(client);

        const ref = new StringStream();

        this.pipe(ref)
            .timeBatch(40, 64)
            .map(messages => ({topic, messages}))
            .pipe(producer);

        return this.whenEnd();
    }
}});

/**
 * @typedef Topic
 * @prop {String} topic topic name in kafka
 * @prop {Number} offset where to start reading
 * @prop {Number} partition kafka partition number
 */
