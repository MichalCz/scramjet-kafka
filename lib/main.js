const {ProducerStream} = require("kafka-node");
const {KafkaStream} = require("./kafka-stream");
const {getConnection} = require("./util");
const scramjet = require("scramjet");
const {DataStream} = scramjet;

/**
 * Scramjet Kafka module exports
 *
 * @type {Object}
 */
module.exports = {
    KafkaStream,

    /**
     * Fetches a stream from Kafka topic performs declared operations and publishes to the another topic.
     *
     * The transforms as in scramjet can be asynchronous, synchronous, even multi-threaded.
     *
     * {@see https://scramjet.eu/ Scramjet documentation}
     *
     * @param  {ZKConnectionOptions} connection Zookeeper connection
     * @param  {String|Topic} fromTopic topic to consume
     * @param  {UseCallback} use transforms callback or scramjet module
     * @param  {String|Topic} toTopic topic to produce3
     * @return {Promise} resolved when fromTopic stream ends.
     */
    async augment(connection, fromTopic, use, toTopic) {    // eslint-disable-line
        return this.from(connection, fromTopic)
            .use(use)
            .toKafka(connection, toTopic);
    },

    /**
     * Consume a topic from kafka and return a new KafkaStream
     *
     * @alias consume
     * @param {String} connection
     * @param {Array.<String|Topic>}  [topics=[]] Topics to pull from Kafka
     * @chainable
     */
    consume(connection, topics) {
        if (!Array.isArray(topics))
            topics = [topics];

        return new KafkaStream(connection)
            .addTopics(topics)
            .connect()
        ;
    }
};

module.exports.from = module.exports.consume;

/**
 * {@link https://scramjet.eu/docs/data-stream.html Scramjet DataStream} plugin - the following methods are added
 * to all scramjet streams
 */
scramjet.plugin({DataStream: {
    /**
     * Plugin to scramjet::DataStream - push to kafka and pull on the other end.
     *
     * This may be used to allow burst flow above memory limits.
     *
     * @memberof plugin
     * @param  {ZKConnectionOptions} connection  Zookeeper connection
     * @param  {String|Topic} [topic=null] topic - will be autogenerated if not given
     * @return {Promise} resolved when fromTopic stream ends.
     */
    viaKafka(connection, topic = null) {
        this.toKafka(connection, topic);
        return new KafkaStream(connection, topic);
    },

    /**
     * Send the stream to the specified Kafka topic.
     *
     * @memberof plugin
     * @param  {ZKConnectionOptions} connection  Zookeeper connection
     * @param  {String|Topic} [topic=null] topic - will be autogenerated if not given
     * @return {Promise} resolved when fromTopic stream ends.
     */
    async produce(connection, topic) {
        const client = getConnection(connection);
        const producer = new ProducerStream(client);

        const ref = new DataStream();

        ref.timeBatch(40, 64)
            .map(messages => ({topic, messages}))
            .pipe(producer);

        return this.whenEnd();
    }
}});

/**
 * @typedef Topic
 * @prop {String} topic topic name in kafka
 * @prop {Number} offset where to start reading
 * @prop {Number} partition kafka partition number
 */
